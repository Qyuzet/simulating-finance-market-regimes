
\PassOptionsToPackage{bookmarks=false}{hyperref}
\documentclass[a4paper,conference,10pt]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{float}
\usepackage{array}
\usepackage{balance}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{url}
\usepackage[font=footnotesize]{caption}
\captionsetup[figure]{labelsep=period, name=Fig.}
\captionsetup[table]{labelsep=period, name=Table}
\renewcommand\IEEEkeywordsname{Keywords}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\raggedbottom

\begin{document}

\title{Conformal Regime Prediction for Robust Portfolio Optimization: A Distribution-Free Framework}

\makeatletter
\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}

\author{
\IEEEauthorblockN{Riki Awal Syahputra}
\IEEEauthorblockA{\textit{Computer Science Department} \\
\textit{Bina Nusantara University} \\
Jakarta, Indonesia \\
riki.syahputra@binus.ac.id}
\and
\IEEEauthorblockN{Darrus Loamayer}
\IEEEauthorblockA{\textit{Computer Science Department} \\
\textit{Bina Nusantara University} \\
Jakarta, Indonesia \\
darrus.loamayer@binus.ac.id}
\and
\IEEEauthorblockN{Yiyang Liu}
\IEEEauthorblockA{\textit{Computer Science Department} \\
\textit{Bina Nusantara University} \\
Jakarta, Indonesia \\
yiyang.liu001@binus.ac.id}
\linebreakand
\IEEEauthorblockN{Nunung Nurul Qomariyah}
\IEEEauthorblockA{\textit{Computer Science Department} \\
\textit{Bina Nusantara University} \\
Jakarta, Indonesia \\
nunung.qomariyah@binus.ac.id}
\and
\IEEEauthorblockN{Raymond Bahana}
\IEEEauthorblockA{\textit{Computer Science Department} \\
\textit{Bina Nusantara University} \\
Jakarta, Indonesia \\
rbahana@binus.edu}
}


\maketitle
\IEEEpubidadjcol

\begin{abstract}
Traditional portfolio optimization methods rely on point predictions of market regimes without quantifying prediction uncertainty, leading to overconfident allocation decisions and substantial losses during regime transitions. Our proposed framework combines and applies unsupervised Hidden Markov Models for market regime identification and a conformal predictor for model-based regime classification and portfolio allocation. When tested on the S\&P~500 dataset for the span of 2010 to 2024 (3,555 samples), the algorithm succeeds in demarcating three distinct market regimes: bear, neutral, and bull markets. Using the gradient boosting classifier and incorporating the conformal model at 90\% target coverage ($\alpha = 0.10$) produces an empirical coverage of 89.82\% with 90.2\% of predictions being high-confidence singletons. When applied to the concept of regime-based allocation, our proposed model produces promising risk-adjusted improvements: a relative risk reduction in the form of 66.2\% for the maximum drawdown and an improved risk-adjusted return (Sharpe ratio) for the proposed strategy (1.520) over the traditional buy and hold strategy (0.814). Here, we also introduce a new adaptive model which combines the adaptive method and the concept of class-conditional quantiles.
\end{abstract}

\begin{IEEEkeywords}
conformal prediction, market regimes, Hidden Markov Models, portfolio optimization, uncertainty quantification, distribution-free inference
\end{IEEEkeywords}

\section{Introduction}

The success of portfolio optimization is dependent on accurate classification of the market regimes, which enables reliable adjustment of the portfolio depending on the prevailing market state. The traditional method provides point estimates of prediction, which classify the market regimes into bear, bull, and neutral regimes depending on the time horizon considered. The method enables successful asset allocation based on the market regimes; however, the estimates lack quantification and may result in optimistic estimates, especially when there is a change in market regimes, hence losing a significant amount of assets due to incorrect market regime classification.

Conformal prediction offers a distribution-free framework for assessing and communicating uncertainty via prediction sets with guarantees of coverage. In comparison to confidence intervals calculated using Bayesian belief and/or bootstrapping, conformal prediction allows for exchangeability in a finite-sample fashion, such that for exchangeable data:
\begin{equation}
P(y_{\text{test}} \in \Gamma(x_{\text{test}})) \geq 1 - \alpha
\end{equation}
where $y_{\text{test}}$ is the true label, $\Gamma(x_{\text{test}})$ is the prediction set for test input $x_{\text{test}}$, and $\alpha$ is the significance level. In the context of exchangeable but perhaps complex financial data, adaptive and sliding-window techniques are investigated. In finance, distributional relationships are often not accurately captured due to heavy tails, regime changes, and/or lack of stationarity.

The research proposal Contributes to the integration of conformal prediction methods into the field of financial regime classification. Although the field of conformal prediction has been widely applied to regression and classification tasks, the current study is one of the first to specifically address the field of financial regime classification. Based on the current state-of-the-art literature, three open problems are outlined in the field of conformal prediction: (1) the empirical analysis of conformal prediction for financial tasks, (2) the computational challenge posed by the issue of unbalanced classes in rarely occurring financial states, and (3) the processing of non-stationary financial time series data. Until now, the current research appears to be the first one to deal with these three problems simultaneously.

It proposes a new paradigm that efficiently integrates the Hidden Markov Model (HMM) regime detection paradigm with conformal prediction in a way that aims at identifying regimes while taking into account predictive risks. The main contributions are: (1) the development of a complete problem chain that connects information in financial markets with portfolios built based on the detected regimes, along with empirical evaluation of coverage; (2) empirical evaluation using a fourteen-year historical series on the S\&P~500 index, proving that the conformal predictor approaches empirical coverage values close to the target value, specifically 89.82\% coverage for $\alpha = 0.10$; (3) the development of portfolios that establish a relationship between predictive risks and risk management, obtaining a 66.2\% reduction in drawdown against a buy-and-hold approach; (4) the development of a new conformal predictor that incorporates adaptive recalibration and class-conditional quantiles, improving balance in coverage and providing a substantial 79.3\% reduction in imbalance in coverage; (5) the empirical evaluation using a wide variety of assets (equities, bonds, and commodities), in order to prove the generality of the proposed paradigm and its dependence on assets.

\section{Related Work}

\textbf{Market Regime Classification.} Regime-switching models have been a major focus area for a very long time in the analysis of financial time series data. The addition of asset allocation based on the different states introduced by Ang and Bekaert~\cite{ang2002} showed the effectiveness of regime-switching models compared to static allocation models during the transition phase. Guidolin and Timmermann~\cite{guidolin2007} further expanded the research area by focusing on the multivariate model, further supporting the use of regime-switching models as valuable tools for improving the portfolio. The role of hidden Markov models has been substantial in the unsupervised approach related to the identification of the regime switch~\cite{nystrup2015,nystrup2017}. These methods and others also have a disadvantage of not providing risk estimates together with the point forecast.

\textbf{Conformal Prediction.} A theoretical framework for conformal predictions has been proposed based on the concept of exchangeability and distribution-free guarantees~\cite{vovk2005}. Later studies on conformal predictions include extensions for time series~\cite{xu2021}, which fail to satisfy the assumption of exchangeability as a consequence of the dependencies among the observed values, and classification settings~\cite{sadinle2019}. Finally, the problem of non-stationarity and changes in the concerned distributions are addressed through adaptive conformal inference~\cite{gibbs2022}. Regarding the use of conformal predictions for the financial regime classification task, a series of issues exist that demand attention, including the evaluation of the empirical coverage for the categorization performance, handling the imbalanced datasets issue, and connection to portfolio-level methods.

\textbf{Uncertainty Quantification in Finance.} Conventional techniques use either the Bayesian approach, which requires prior specification and distributional assumptions, or the bootstrap resampling method, which requires large sample sizes and assumes stationarity. These methods face challenges when addressing the fat-tailed and non-stationary properties of financial returns. To the best of our knowledge, this study is one of the first to use the conformal prediction method for regime-based portfolio optimization in the literature. We address the current open issues in the literature by proposing a new hybrid solution.

\section{Methodology}

\subsection{Data and Features}

\textbf{Dataset Scope.} We use S\&P~500 Index data on a daily timescale, covering the period from November 2010 to December 2024, which, after preprocessing, provides us with 3,555 data points. Data on market variables is sourced from Yahoo Finance, including stock prices, market volumes, and VIX, while data on macrovariables includes economic data from the Federal Reserve Economic Data (FRED), which focuses on the Targeted Fed Funds Rate and the Consumer Price Index. This covers fourteen years, spanning several full economic cycles, including the recovery from the financial crisis of 2008, the COVID crash and subsequent recovery in 2020--2021, the market crash in 2022, and finally, the market recovery in 2023 and 2024.

\textbf{Feature Engineering.} We construct a set of 28 variables, which are divided into six groups. First, return variables include both simple return and log return, which have been demonstrated to have desirable properties for time series analysis. Second, market risk variables measure market risk profiles on different horizons by computing the standard deviation on a 20-day, 30-day, and 60-day basis. Third, momentum variables measure the degree of trend on a 10-day, 20-day, and 60-day basis. Fourth, technical variables include analysis on moving averages on a 10-day, 20-day, 50-day, and 200-day basis, as well as the ratio of price to moving averages, the Relative Strength Index, and the Moving Average Convergence/Divergence indicator. Fifth, volume variables measure market activity through such variables as percentage changes in volumes and moving averages. Lastly, the set also includes the VIX, Federal Funds Rate, and year-over-year CPI inflation as macroeconomic information variables.

In the case of conformal prediction classification, six base features are chosen to be log returns, volatility over 30 days, momentum over 20 days, RSI, MACD, and the Federal Funds Rate, each of which is appended with features that have been lagged over 1, 5, 10, and 20 days. This gives a total of 30 features.

\textbf{Data Preparation.} These 199 observations are therefore removed as part of the burn-in process for the initialization of the 200-day moving average. The remaining observations are 3,555 observations from November 12, 2010, to December 30, 2024. On the other hand, the identification of outliers utilizing the interquartile range approach shows that the return series has been identified as outliers for 52 observations (1.46\%), the volatility series for 54 observations (1.52\%), and the volume series for 84 observations (2.36\%). However, these observations are retained as they resemble actual market events like the COVID-19 crash and the bear market of 2022 that helped in the identification of regimes. Further, the return series has a skewness value of $-0.87$ and a kurtosis value of 18.45.

\subsection{Hidden Markov Model for Regime Discovery}

\textbf{Model Specification.} For the inference of the possible hidden states based on the underlying data, we use a three-state Gaussian hidden Markov model. In the proposed model, we use three features: return, volatility, and momentum. They are all mutually complementary features. To define the hidden states, we use a $3 \times 3$ state transition matrix $A$, where $A_{ij}$ is the transition probability from state $i$ to state $j$. To define the states as observations, we use a multivariate Gaussian $\mathcal{N}(\mu_i, \Sigma_i)$ for each state $i$. Here, the hidden states are defined as $\{s_0, s_1, s_2\}$, where $\mu_i$ is a mean vector and the state covariance is the full covariance matrix $\Sigma_i$. Therefore, the model considers the correlation between the features for the states.

\textbf{Training and Labeling.} The parameters for the Hidden Markov Model (HMM) are then estimated using the Baum--Welch algorithm, a procedure that maximizes the log-likelihood of the observed sequence data. In the Baum--Welch algorithm, the parameters for the HMM are estimated using the transition probability matrix $A$, the emission means $\mu_i$, and the covariance matrices $\Sigma_i$. In the algorithm, the process runs for a total of 1,000 iterations, and the random seed is set to 42. Once the algorithm is finished, the Viterbi algorithm is then used to determine the assignment of each observation to its most likely state. Because the states in the HMM are unlabeled, the labeling process is based on the states' mean return values, where the state with the lowest mean return is called the ``bear market,'' the state with the highest mean return is called the ``bull market,'' and the remaining state is the ``neutral market.''

\textbf{Empirical Results.} When the proposed methodological framework is used on the S\&P~500 index over the 2010--2024 timeframe, three states emerge that correspond to specific statistical patterns. The bear market state corresponds to 18.1\% (645 days) of the timeframe and features a negative mean return of $-0.04\%$ and high volatility of 1.79\%, matching the COVID-19 market crash in 2020 and the 2022 bear market. Indeed, the bull market state, the largest state, covers 47.9\% (1,703 days) and features a positive mean return of 0.08\% and low volatility of 0.56\%, similar to the post-financial crisis expansion. Finally, the neutral market state covers 34.0\% (1,207 days) and features a moderate mean return and volatility of 0.06\% and 0.94\%, respectively.

\textbf{HMM Sensitivity.} The assignment of the regime is dependent on both the initialization of the Gaussian Hidden Markov Model (HMM) and the choice of the number of states. After evaluating models with 2--5 states based on BIC and AIC, a three-state Gaussian HMM was selected. The outcome of the sensitivity analysis is shown in the supplementary information.

% FIGURE 1: HMM Regime Distribution
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/figures/hmm_regime_distribution.png}
\caption{HMM regime distribution showing temporal evolution of bear, bull, and neutral regimes across the 2010-2024 period.}
\label{fig:hmm_regime}
\end{figure}

% FIGURE 2: Regime Characteristics
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/figures/regime_characteristics.png}
\caption{Statistical characteristics of discovered regimes including mean returns, volatility, and duration distributions.}
\label{fig:regime_char}
\end{figure}

\subsection{Conformal Prediction Framework}

\textbf{Data Splitting.} The conformal prediction setup demands a splitting into three parts that respects the temporal ordering. The data is divided into three parts based on their temporal ordering: Calibration (20.0\%, 712 examples) for calculating conformity scores and quantiles; Calibration \& Validation for the formulation of Hidden Markov models and learning the classifier (60.1\%, 2,136 examples) split into two parts - Calibration for conformity scores and quantiles, and Calibration \& Validation for Hidden Markov models and classifier learning; and a Testing part (19.9\%, 707 examples) for predicting on new examples. Stratified sampling is used for dividing the data into the aforementioned three parts. The importance lies in distributing the data into these three parts based on temporal blocks and not distributing examples across different time points. Although this stratification helps in the availability of examples for different regimes, it does not lead to exchangeability. Thus, the coverage probabilities are considered empirical.

\textbf{Base Classifier.} We use a Gradient Boosting Classifier for our regime prediction task, choosing this model because of its proven strength on tabular data, model interpretability through feature importances, and efficiency. The model uses a sequential approach to construct an ensemble of decision trees, each of which attempts to correct for mistakes of its predecessor models by modeling errors. Setup for this model: 100 estimators, 0.1 learning rate, a max depth of 5, random state of 42. On evaluation with regular point predictions (argmax of class probabilities), our model achieved a single hold-out test accuracy of 97.31\%.

\textbf{Conformal Algorithm.} Using the calibration dataset $\{(x_i, y_i)\}_{i=1}^n$ and the base classifier $f: X \to \Delta^{K-1}$ (regime classes $K=3$) estimating class probabilities, we build the prediction set $\Gamma_\alpha(x)$ with a coverage $P(y \in \Gamma_\alpha(x)) \geq 1-\alpha$ in the four steps. First, we train the classifier $f$ on a training dataset using standard gradient boosting. Second, we calculate nonconformity scores for the dataset $\{(x_i, y_i)\}_{i=1}^n$: we calculate for each pair $(x_i, y_i)$ the value $s_i = 1 - f(x_i)[y_i]$ for the predicted probability $f(x_i)[y_i]$. The standard inverse probability nonconformity score is used; however, margin-based scores are described in Section IV. Smaller values correspond to more conforming points. Third, we calculate the conformal quantile $\hat{q}_\alpha$ for the fixed level $1-\alpha$ based on the empirical distribution function of the nonconformity scores. Finally, the prediction sets for the test instance $x$ are defined as $\Gamma_\alpha(x$).

\textbf{Coverage Levels.} We consider significance levels for different levels of coverage efficiency: $\alpha = 0.20$ for 80\% coverage and sets of smaller sizes, $\alpha = 0.10$ for 90\% coverage and a balanced efficiency level, and $\alpha = 0.05$ for 95\% coverage and sets of larger sizes.

\subsection{Portfolio Optimization}

\textbf{Regime-Based Allocation Rules.} Based on the regime and its associated risk and return profiles, we make financial asset allocations through regime-specific rules. In the bear market (suggested by negative returns and high volatility), the rule specifies allocating 20\% of the financial assets to equity and 80\% to cash, focusing on capital protection. In the bull market (suggested by positive returns and low volatility), the rule specifies allocating 100\% of the financial assets to equity and 0\% to cash, aiming at growth maximization. In the neutral market (suggested by moderate returns and volatility), the rule specifies allocating 60\% of the financial assets to equity and 40\% to cash, aiming at balance. These rules are intentionally kept simplistic instead of optimizing them, thus extracting the benefit of the uncertainty quantification achieved in conformal prediction.

\textbf{Backtest Assumptions.} The allocations are made at the closing prices of a day, taking into account the specified cost of trading per transaction. Slippage and market impact are assumed to be captured just by the cost of trading per transaction. Fractional positions are allowed. In the CP Conservative strategy, there are 146 trades during the testing period (evaluation period from 2021--2024, a total of 707 days).

\textbf{Point Prediction Strategy (Baseline).} The traditional method chooses the regime with the highest probability scored by the classifier (argmax), thereby making a prediction regarding the regime, and then the allocation is made accordingly. One major drawback of the above method is that it gives equal importance to the prediction made by the classifier when it is 51\% and when it is 99\%, thereby overlooking the confidence level. This may lead to overtrading during uncertain periods.

\textbf{CP Conservative Strategy.}The new approach combines prediction uncertainty through sets. An empty set indicates a situation with high uncertainty, which implies 0\% equity, or purely cash positions. A singleton set indicates a situation with a high level of certainty, which implies use of standard regime allocation rules. A multi-regime set indicates a situation with some level of uncertainty, where equity allocation depends on finding a worst case: $w_{equity} = \min_{r \in \Gamma(x)} w_r$.

\textbf{CP Average Strategy.} Alternative formulation: the empty sets correspond to cash allocation, singleton sets correspond to standard allocation, and multi-regime sets use average allocation $w_{equity} = \frac{1}{|\Gamma(x)|} \sum_{r \in \Gamma(x)} w_r$. This formulation embodies a balance between being overly risk-averse and ignoring uncertainty in point predictions. It is worth mentioning that for $\alpha = 0.10$, there will be no multi-class sets, so both CP Conservative and CP Average will be identical; for other levels of significance, $\alpha = 0.20$, for example, there can be multi-class sets, so the strategies will be different.

\subsection{Evaluation Metrics}

\textbf{Conformal Prediction Metrics.} Coverage measures the proportion of test samples for which the true regime is included in the predicted region, thus confirming the theoretical coverage guarantee $P(y \in \Gamma(x)) \ge 1-\alpha$. Average set size measures the average number of regimes included in the predicted region, measuring the efficiency (with lower values being preferred). Singleton rate measures the proportion of the test samples for which a unique regime is included in the region, hence measuring a region of high confidence, while the empty rate measures the proportion for which the region is empty, thus measuring a region of extreme uncertainty.

\textbf{Portfolio Performance Metrics.} Total Return measures the cumulative percentage increase that was identified over the test period. Sharpe Ratio focuses on risk-adjusted returns, the ratio of average excess returns to its volatility. Sortino Ratio is the enhanced form of Sharpe Ratio that considers downside volatility alone. Maximum Drawdown measures the largest decline between the high point and the lowest point, thus testing capital preservation. Calmar Ratio measures the ratio of annualized returns relative to maximum drawdown, that is, the return per worst case risk.

\textbf{Statistical Validation.} Fivefold stratification cross-validation estimates the mean accuracy on the temporal folds. Bootstrap confidence intervals are used with a confidence level of 95\%, which provides insight into the uncertainty surrounding estimates of performances. Permutation tests are conducted as a sanity check through random label permutation, where the results are interpreted descriptively.

\section{Results}

\subsection{Conformal Prediction Performance}

\textbf{Coverage Validation.} Table \ref{tab:coverage} shows the results for coverage for different significance levels. These results show that conformal prediction results in empirical coverage that is very close to the target values. For $\alpha = 0.20$ or 80\% coverage, the empirical coverage is 80.62\%, which is a deviation of +0.62 percentage points. For $\alpha = 0.10$ or 90\% coverage, the empirical coverage is 89.82\%, which is a deviation of -1.18 percentage points. For $\alpha = 0.05$ or 95\% coverage, the empirical coverage is 94.77\%, which is a deviation of -0.23 percentage points. All significance levels achieve coverage with a deviation of less than 1.5 percentage points. Thus, these results confirm the empirical coverage. It is worth noting that this is a nonstationary and heavy-tailed financial series. All traditional methods for uncertainty quantification assume otherwise.

\begin{table}[h]
\centering
\caption{Coverage Results Across Significance Levels}
\label{tab:coverage}
\begin{tabular}{@{}lcccc@{}}
\toprule
$\alpha$ & Expected & Actual & Difference & Status \\ \midrule
0.20 & 80.0\% & 80.62\% & +0.62\% & Pass \\
0.10 & 90.0\% & 89.82\% & -1.18\% & Pass \\
0.05 & 95.0\% & 94.77\% & -0.23\% & Pass \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Prediction Set Efficiency.} Table \ref{tab:setsize} shows the distribution of the prediction sets for $\alpha = 0.10$. Notice that 90.2\% of the prediction sets are singletons (638 out of 707), which reflects the confidence of the model in its point estimates and uncertainty. The 9.8\% empty prediction sets (69 out of 707) represent the true regime ambiguities that make the model reluctant to provide overly optimistic estimates. Moreover, the multi-class prediction sets are 0\% (0 out of 707), which shows that no instance of multi-regime ambiguity exists. The set size is on average 0.90, giving the prediction efficiency a value of 99.8\% (computed from $89.82\%/0.90$). The empty prediction set happens when the probability values for all classes lie below the conformal boundary. This boundary represents the so-called known threshold of extremal uncertainty to establish the value of the cash position. Other measures of nonconformity, like scores based on margins (\texttt{prob\_max - prob\_second}), or scaled p-values, could be used in future studies for dealing with the problem of empty sets of predictions. However, the fact that singletons are far more frequent than empties clearly shows that conformal predictors provide reliable informative signals on most days, while resorting to signals of uncertainty only in times of high ambiguity. When testing at other significance levels, similar findings can be obtained; at $\alpha = 0.20$, for example, the respective values are 80.6\% singletons, 19.4\% empties, and 0\% multi-class, while at $\alpha = 0.05$, there are 96.3\% singletons, 3.7\% empties, and 0\% multi-class predictions. It must be noted that 97.31\% represents the single holdout test accuracy on the temporal split, while 97.74\% represents the average accuracy over five-fold temporal cross-validation.

% FIGURE 3: Conformal Analysis
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/conformal_prediction/conformal_analysis.png}
\caption{Conformal prediction analysis showing coverage rates, set size distributions, and calibration quality across significance levels.}
\label{fig:conformal_analysis}
\end{figure}

\begin{table}[h]
\centering
\caption{Set Size Distribution ($\alpha=0.10$)}
\label{tab:setsize}
\begin{tabular}{@{}lccc@{}}
\toprule
Set Size & Count & Percentage & Interpretation \\ \midrule
0 (empty) & 69 & 9.8\% & Very uncertain \\
1 (singleton) & 638 & 90.2\% & Certain \\
2-3 (multi) & 0 & 0.0\% & Moderately uncertain \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Coverage by Regime.} From Table \ref{tab:regime_coverage}, the coverage varies across regimes, reflecting the inherent difficulty in predicting different market conditions. The coverage for the Bear regime is 88.4\% (number of samples = 129), the Bull regime at 93.8\% (number of samples = 340), and the Neutral regime at 84.9\% (number of samples = 238). While the overall coverage of 89.8\% is close to the target of 90\%, the variation across regimes (ranging from 84.9\% to 93.8\%) indicates that certain regimes are more challenging to predict with high confidence. The Bull regime shows the highest coverage, suggesting that bullish market conditions produce more confident predictions, while the Neutral regime shows lower coverage, reflecting the inherent ambiguity in sideways market movements. This variation is expected in financial markets where regime characteristics differ substantially, and the conformal predictor appropriately reflects this uncertainty through its prediction sets.

% FIGURE 4: Method Comparison
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/conformal_prediction/comparison.png}
\caption{Comparison of baseline, class-conditional, adaptive, and hybrid conformal prediction methods across coverage and efficiency metrics.}
\label{fig:cp_comparison}
\end{figure}

\begin{table}[h]
\centering
\caption{Coverage by Regime ($\alpha=0.10$)}
\label{tab:regime_coverage}
\begin{tabular}{@{}lcccc@{}}
\toprule
Regime & Coverage & Samples & Expected & Difference \\ \midrule
Bear & 88.4\% & 129 & 90.0\% & -1.6\% \\
Bull & 93.8\% & 340 & 90.0\% & +3.8\% \\
Neutral & 84.9\% & 238 & 90.0\% & -5.1\% \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Comparison with Point Predictions.} Table \ref{tab:point_vs_cp} compares traditional point prediction with conformal prediction. The point predictor has an accuracy of 97.31\%, but with no provision for any measure of the associated uncertainties. At the level of error $\alpha = 0.10$, the coverage for the conformal predictor is 89.82\%, reflecting a reduction of 7.49 percentage points relative to the point predictor, but with explicit provision for the uncertainties via the size of prediction sets and verification by empirical coverage. At the more stringent level $\alpha = 0.05$, the coverage using the conformal predictor is 94.77\%, very close to the accuracy level of the point predictor, but with explicit provision for the uncertainties.

\begin{table}[h]
\centering
\caption{Point Predictions vs Conformal Predictions (Accuracy is reported for point prediction; empirical coverage is reported for conformal methods)}
\label{tab:point_vs_cp}
\begin{tabular}{@{}lccc@{}}
\toprule
Method & Metric Value & Uncertainty & Guarantee \\ \midrule
Point Prediction & 97.31\% & No & No \\
CP ($\alpha=0.10$) & 89.82\% & Yes (set size) & Yes ($\geq$90\%) \\
CP ($\alpha=0.05$) & 94.77\% & Yes (set size) & Yes ($\geq$95\%) \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Portfolio Performance}

% FIGURE 5: Portfolio Performance
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/cp_portfolio/portfolio_performance.png}
\caption{Cumulative returns comparison across buy-and-hold, point prediction, and conformal prediction strategies over the test period.}
\label{fig:portfolio_perf}
\end{figure}

\textbf{Strategy Comparison.} Table \ref{tab:portfolio} outlines the comparison of the strategies during the evaluation period (2021--2024). From the table, the strategy with the highest possible return is the Point Prediction strategy, giving a return of 66.50\%, a Sharpe ratio of 1.527, and a maximum drawdown of -10.49\%, showing that the strategy performs well when the regime predictions are good. The strategy giving a return of 47.35\%, a Sharpe ratio of 1.520, and a maximum drawdown of -8.60\%, which is a relative drawdown reduction of 66.2\%, is the CP Conservative strategy. While the strategy performs poorly on the absolute return during a bull market scenario like the one prevailing during the evaluation period, its ability to offer risk protection to risk-averse investors cannot be overemphasized.

\textbf{Risk-Return Trade-off.} There is a performance gap between the results of Point Prediction (66.50\%) and CP Conservative (47.35\%) because the latter applies an allocation method sensitive to uncertainty. When the conformal predictor produces an empty set (happens on 35.1\% of days), the CP Conservative strategy allocates to cash, thus forgoing any gains and losses on days of uncertainty. This risk-aversion strategy explains the lower return but improved protection against losses (-8.60\% vs. -10.49\% for Point Prediction, a relative improvement of 18.1\%).

\begin{table}[h]
\centering
\caption{Portfolio Strategy Comparison (2021-2024)}
\label{tab:portfolio}
\begin{tabular}{@{}lccccc@{}}
\toprule
Strategy & Total & Annual & Sharpe & Max DD & Win \\
 & Return & Return & Ratio &  & Rate \\ \midrule
Buy \& Hold & 69.88\% & 13.41\% & 0.814 & -25.43\% & N/A \\
Point Prediction & 66.50\% & 12.87\% & 1.527 & -10.49\% & 52.3\% \\
CP Conservative & 47.35\% & 9.64\% & 1.520 & -8.60\% & 35.3\% \\
CP Average & 47.35\% & 9.64\% & 1.520 & -8.60\% & 35.3\% \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Risk Metrics Analysis.} Win rate represents the percentage of days with positive returns and is only shown for completeness. In Table~\ref{tab:risk}, the CP Conservative strategy achieves the lowest volatility on an annual basis (6.35\% vs. 8.43\% Point Prediction, a reduction of 24.7\%), a strong Sortino ratio (2.03 vs. 2.34, a difference of 13.2\%), and a comparable Calmar ratio (1.12 vs. 1.23). Its high Sortino ratio value shows that the reduction in volatility mainly comes from avoiding downside risk rather than limiting upside potential, which is very desirable in managing risk asymmetry. Its volatility of 6.35\% represents a reduction of 61.4\% over buy-and-hold with a volatility of 16.47\%. This shows that there is significant risk mitigation through regime-conscious investing.

\begin{table}[h]
\centering
\caption{Risk Metrics Comparison}
\label{tab:risk}
\begin{tabular}{@{}lcccc@{}}
\toprule
Strategy & Annual Vol & Sharpe & Sortino & Calmar \\ \midrule
Buy \& Hold & 16.47\% & 0.814 & 1.14 & 0.53 \\
Point Prediction & 8.43\% & 1.527 & 2.34 & 1.23 \\
CP Conservative & 6.35\% & 1.520 & 2.03 & 1.12 \\ \bottomrule
\end{tabular}
\end{table}

Based on allocation dynamics (Table~\ref{tab:allocation}), it can be noted that on 19.0\% of days, the strategy holds 100\% equity based on confident bullish forecasts, on 26.7\% of days it holds 60\% equity based on neutral forecasts, on 19.2\% of days it holds 20\% equity based on bear regime predictions, while on 35.1\% of days it holds 0\% equity based on empty prediction sets or times of uncertainty.

% FIGURE 6: Allocation Dynamics
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/cp_portfolio/allocation_dynamics.png}
\caption{Time series of portfolio allocation decisions showing adaptive equity exposure based on conformal prediction set composition.}
\label{fig:allocation}
\end{figure}

\begin{table}[h]
\centering
\caption{Position Size Distribution (CP Conservative, $\alpha=0.10$)}
\label{tab:allocation}
\begin{tabular}{@{}lccc@{}}
\toprule
Allocation & Days & Percentage & Regime Context \\ \midrule
0\% (cash) & 372 & 35.1\% & Empty prediction set \\
20\% (bear) & 204 & 19.2\% & Bear regime predicted \\
60\% (neutral) & 283 & 26.7\% & Neutral regime predicted \\
100\% (bull) & 202 & 19.0\% & Bull regime predicted \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Statistical Validation}

\textbf{Cross-Validation.} We performed a 5-fold stratified cross-validation to assess the robustness of the model over the temporal divisions. The results for the different folds are shown in Table \ref{tab:cv_results}. The average cross-validation accuracy is 97.74\% (standard deviation 0.56\%), while the single holdout accuracy is 97.31\%, values obtained from different evaluation procedures and hence not comparable. The average coverage is 95.53\% with 0.65\% standard deviation. The 95\% confidence intervals for the small sample size are obtained by the t-distribution, namely accuracy [96.76\%, 98.71\%] and coverage [94.40\%, 96.66\%]. The high values of the cross-validation coverage are due to the specific division of the folds into calibration set and are hence not comparable with the single holdout values. The low values of the standard deviation for the different quantities are well below 1\% and confirm the robustness of the performance for different temporal divisions.

\begin{table}[h]
\centering
\caption{5-Fold Cross-Validation Results}
\label{tab:cv_results}
\begin{tabular}{@{}lcc@{}}
\toprule
Fold & Accuracy & Coverage ($\alpha=0.10$) \\ \midrule
Fold 1 & 97.60\% & 95.47\% \\
Fold 2 & 97.03\% & 94.91\% \\
Fold 3 & 97.74\% & 95.19\% \\
Fold 4 & 98.59\% & 96.61\% \\
Fold 5 & 97.74\% & 95.47\% \\ \midrule
Mean & 97.74\% & 95.53\% \\
Std Dev & 0.56\% & 0.65\% \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Bootstrap Validation.} For the bootstrapping process, we used 1,000 iterations. The 95\% confidence intervals for the remaining variables are as follows: coverage [89.82\%, 92.36\%], Sharpe ratio [0.95, 1.27], and maximum drawdown [-11.45\%, -9.12\%]. The 95\% confidence interval for coverage [89.82\%, 92.36\%] is very close to the target level of 90\%, hence representing validity within sample variability. For the remaining metrics, the confidence intervals do not include the baseline performance of the buy-and-hold strategy with Sharpe ratio of 0.814 and maximum drawdown of -25.43\%.

\textbf{Permutation Test.} A permutation test with a total of 100 iterations was performed as a sanity check. The performance is found to be much poorer when subject to random permutations of the labels; however, validity for hypothesis testing is not guaranteed at this point. For hypothesis tests, we recommend that at least 1,000 permutations be performed. These will be considered for the further analysis.

\textbf{State-of-the-Art Comparison.} We compare the performance of the Gradient Boosting classifier with that of a deep learning model based on the Transformer architecture (with Temporal Fusion Transformer specifications of 4 layers, 128 hidden units in each layer, and 8 attention heads) on the same sets of features. We present a comparison on various performance metrics in Table \ref{tab:sota}. The Gradient Boosting method is able to achieve a classification accuracy of 97.74\%, while the Transformer is able to achieve a similar goal with a slightly lower accuracy value of 96.89\% (with a relative improvement of 0.85\%). Additionally, the Gradient Boosting model is able to train much faster compared to the Transformer model (39.31 seconds), taking just around 5--10 seconds for training (with a relative improvement of $5.6\times$ faster). It is worth noting that the hyperparameter tuning for the models was performed as suggested by standard configurations recommended in previous literature and not as part of exhaustive hyperparameter tuning.

\begin{table}[h]
\centering
\caption{State-of-the-Art Model Comparison (Intel i7-10700K, 32GB RAM, single runs)}
\label{tab:sota}
\begin{tabular}{@{}lcccc@{}}
\toprule
Model & Accuracy & Training Time & Complexity & Interpret. \\ \midrule
Gradient Boosting & 97.74\% & 5-10s & Simple & High \\
Transformer (TFT) & 96.89\% & 39.31s & Complex & Low \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Enhanced Conformal Prediction Methods}

We study three variants of conformal prediction with a high level of complexity to find answers for open questions that were discovered in recent literature, including class-conditional conformal prediction for handling class imbalance, adaptive conformal prediction for non-stationary time series, and a new scheme combining both.

\textbf{Class-Conditional CP.} The standard conformal predictor (CP) fixes a quantile for a particular class. Generally, this method provides imbalanced results, especially when there is a large gap between class distributions. For the problem at hand, the class distributions for bear, bull, and neutral are fixed at 18.1\%, 47.9\%, and 34.0\%, respectively. Using a class-conditional CP method allows the definition of class quantiles by defining different classes, and calibration sets are fixed for a particular class. The outputs are summarized in Table \ref{tab:class_cond}. The standard deviation of class coverage is drastically reduced from values of 4.61\% to 1.57\%, giving a relative reduction of 66.0\%, which is a significant reduction. Hence, for the bear class, the coverage is improved from 88.37\% to 91.47\%, giving a relative improvement of +3.10\%. Also, for the bull class, the coverage is improved from 93.82\% to 92.35\%, giving a relative change of -1.47\%. For the neutral class, the coverage is improved from 84.87\% to 89.08\%, giving a relative improvement of +4.21\%. Overall coverage improves from 89.82\% to 91.09\%, achieving the target 90\% coverage while substantially improving balance across regimes.

\begin{table}[h]
\centering
\caption{Class-Conditional CP Results}
\label{tab:class_cond}
\begin{tabular}{@{}lcccccc@{}}
\toprule
Method & Overall & Bear & Bull & Neutral & Set Size & Std Dev \\ \midrule
Standard CP & 89.82\% & 88.37\% & 93.82\% & 84.87\% & 0.90 & 4.61\% \\
Class-Cond & 91.09\% & 91.47\% & 92.35\% & 89.08\% & 0.92 & 1.57\% \\
Improvement & +1.27\% & +3.10\% & -1.47\% & +4.21\% & +0.02 & -66.0\% \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Adaptive CP.} Financial time series data are not stationary, exhibiting regime change patterns. Adaptive conformal prediction (CP) methods use the concept of a window to update the quantile values when new data points are obtained. Results are obtained using three window values: 126 days, 252 days, and 504 days, equivalent to 6 months, 1 year, and 2 years, respectively. Results in Table \ref{tab:adaptive} show that all window values have achieved valid empirical coverage values between 89.82\% and 90.38\%, and the optimal window value that considers recent regime change patterns and satisfies statistical stability is 126 days.

\begin{table}[h]
\centering
\caption{Adaptive CP Results (Different Window Sizes)}
\label{tab:adaptive}
\begin{tabular}{@{}lccccc@{}}
\toprule
Window Size & Overall & Bear & Bull & Neutral & Set Size \\ \midrule
126 days (0.5yr) & 90.38\% & 90.70\% & 94.41\% & 84.45\% & 0.91 \\
252 days (1.0yr) & 89.82\% & 89.15\% & 93.82\% & 84.45\% & 0.90 \\
504 days (2.0yr) & 90.24\% & 89.15\% & 94.12\% & 85.29\% & 0.91 \\
Standard CP & 89.82\% & 88.37\% & 93.82\% & 84.87\% & 0.90 \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Hybrid CP (Novel Contribution).} We propose a new type of hybrid model that incorporates adaptive calibration with class-conditional quantiles, while keeping separate buffers for each regime class. These details are shown in Table \ref{tab:hybrid}. Results show that our proposed hybrid model achieves superior coverage balance across regimes: standard deviation of 0.95\%, which represents a 79.3\% improvement over the baseline value, bear coverage of 91.47\% (+3.10\% over the baseline), neutral coverage of 90.76\% (+5.89\% improvement), and bull coverage of 87.35\%. While the overall coverage of 89.25\% is slightly below the 90\% target, the model demonstrates the most consistent performance across all three market regimes. In general, our proposed hybrid model performs the best among all models in terms of coverage balance across regimes. It is an empirical model that does not provide any theoretical guarantees on coverage. Validity will be proven using out-of-sample testing.

\begin{table}[h]
\centering
\caption{Hybrid CP Results - Novel Contribution}
\label{tab:hybrid}
{\small
\begin{tabular}{@{}lcccccc@{}}
\toprule
Method & Ovr. & Bear & Bull & Neut. & Size & SD \\ \midrule
Standard CP & 89.82 & 88.37 & 93.82 & 84.87 & 0.90 & 4.61 \\
Class-Cond & 91.09 & 91.47 & 92.35 & 89.08 & 0.92 & 1.57 \\
Adaptive (126) & 90.38 & 90.70 & 94.41 & 84.45 & 0.91 & 4.29 \\
\textbf{Hybrid (126)} & \textbf{89.25} & \textbf{91.47} & \textbf{87.35} & \textbf{90.76} & \textbf{0.90} & \textbf{0.95} \\
Improvement & -0.57 & +3.10 & -6.47 & +5.89 & 0.00 & -79.3 \\ \bottomrule
\end{tabular}
}
\vspace{-2mm}
\footnotesize{All coverage values in \%. SD = Std Dev of coverage across regimes.}
\end{table}

In summary, the performance of each method is presented in Table \ref{tab:enhanced_cp}, where it may be observed that the hybrid method achieves the best coverage balance with a standard deviation of 0.95\%, along with strong performance on rare event coverage with bear regime at 91.47\% and neutral regime at 90.76\%.

\begin{table}[h]
\centering
\caption{Enhanced Conformal Prediction Methods Comparison}
\label{tab:enhanced_cp}
\begin{tabular}{@{}lccccc@{}}
\toprule
Method & Overall & Bear & Bull & Neutral & Std Dev \\ \midrule
Standard CP & 89.82\% & 88.37\% & 93.82\% & 84.87\% & 4.61\% \\
Class-Cond & 91.09\% & 91.47\% & 92.35\% & 89.08\% & 1.57\% \\
Adaptive & 90.38\% & 90.70\% & 94.41\% & 84.45\% & 4.29\% \\
\textbf{Hybrid} & \textbf{89.25\%} & \textbf{91.47\%} & \textbf{87.35\%} & \textbf{90.76\%} & \textbf{0.95\%} \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Transaction Cost Sensitivity}

We examine the robustness of the portfolio strategy with respect to four different transaction cost values: 0.00\% (frictionless), 0.05\% (institutional trading), 0.10\% (retail trading), and 0.20\% (high cost). Table \ref{tab:transaction_cost} illustrates the decrease of the Sharpe ratio under increasing transaction costs. For a cost of 0.10\%, which is more realistic for retail, the Sharpe ratio of the CP Conservative strategy is 1.013, which is a relative improvement of 28.4\% over buy-and-hold (Sharpe ratio of 0.789), even with more frequent trades of 146 over buy-and-hold, which did not make any trades. The decrease of the Sharpe ratio from the frictionless scenario to the high cost scenario is larger by 50.7\% for CP, compared with 21.9\% for point prediction, because CP algorithms make more trades. However, all CP algorithms stay profitable, which reinforces the idea that these algorithms indeed work well under realistic transaction costs.

\begin{table}[h]
\centering
\caption{Portfolio Performance Under Transaction Costs (Sharpe Ratios)}
\label{tab:transaction_cost}
\begin{tabular}{@{}lcccc@{}}
\toprule
Strategy & 0.00\% & 0.05\% & 0.10\% & 0.20\% \\ \midrule
Buy \& Hold & 0.789 & 0.789 & 0.789 & 0.789 \\
Point Prediction & 1.281 & 1.210 & 1.140 & 1.001 \\
CP Conservative & 1.361 & 1.186 & \textbf{1.013} & 0.671 \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Multi-Asset Validation}

To test the overall validity of the framework on multiple assets simultaneously, we apply standard conformal prediction (CP) and class-conditional conformal prediction to five assets over three classes: equity (SPY), technology equity (QQQ), small-cap equity (IWM), fixed income (TLT), and commodities (GLD). The multi-asset performance metrics are tabulated in Table \ref{tab:multiasset}. The overall mean coverage for multiple assets is 88.4\% for standard conformal prediction and 83.5\% for class-conditional conformal prediction. The highest coverage is for equities (QQQ = 90.7\%, IWM = 93.2\%) and the lowest for the fixed income class (TLT set size = 1.68). Notably, class-conditional prediction algorithms improve fixed income class coverage (TLT +6.9\%, balance 10.9\% to 0.9\%) and deteriorate commodities class coverage (GLD -29.4\%, balance 2.2\% to 31.9\%). This suggests the requirement for asset class-specific calibration. Due to the distinct regime dynamics for the various assets and lack of exchangeability among them, we strictly calibrate and validate the conformal framework on each individual asset.

\begin{table}[h]
\centering
\caption{Multi-Asset Conformal Prediction Performance}
\label{tab:multiasset}
\begin{tabular}{@{}lcccc@{}}
\toprule
Asset & Class & Std CP & CC CP & Set Size \\ \midrule
SPY & Equity & 78.8\% & 81.8\% & 0.80 \\
QQQ & Equity & 90.7\% & 90.2\% & 0.96 \\
IWM & Equity & 93.2\% & 88.7\% & 0.96 \\
TLT & Bonds & 84.6\% & 91.5\% & 1.68 \\
GLD & Commodity & 94.6\% & 65.2\% & 1.60 \\ \midrule
Mean & - & 88.4\% & 83.5\% & 1.20 \\ \bottomrule
\end{tabular}
\end{table}

% FIGURE 7: Multi-Market Analysis (Optional)
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/figures/multi_market_analysis.png}
\caption{Regime classification performance across multiple geographic markets demonstrating framework generalizability.}
\label{fig:multi_market}
\end{figure}

% FIGURE 8: Baseline Comparison (Optional)
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/figures/baseline_comparison.png}
\caption{Performance comparison against baseline methods including naive prediction and traditional uncertainty quantification approaches.}
\label{fig:baseline}
\end{figure}

\section{Discussion}

\subsection{Validation of Theoretical Guarantees}

Our results show that conformal prediction provides empirical coverage close to theoretical levels, especially for financial regime classification, which can be considered a challenging environment. In fact, the empirical coverage level of 89.82\% at a significance level of $\alpha = 0.10$ is within 1.18 percentage points of the theoretical target of 90\%, with deviation levels below 1.5 percentage points at all tested significance levels. It should be noted that financial data tends to be non-stationary and heavy-tailed, violating all assumptions related to uncertainty quantification techniques.

Also, a very high singleton probability (90.2\%) indicates that conformal prediction provides a definitive answer for a large fraction of days, performing equally well as point prediction while also accounting for uncertainty estimation. The moderate rate of empty sets (35.1\% in out-of-sample testing) reflects a state of regime uncertainty, where conformal prediction correctly indicates uncertainty instead of producing overconfident predictions. Empty prediction sets are a deliberate form of abstention, as they are not failures to classify, which can then benefit a subsequent decision rule, such as cash allocation in portfolio investment, as demonstrated below during the 2022 transition into a bear market, where cash allocation was triggered when there were empty prediction sets to avoid large drawdowns.

Regime-specific coverage (Bear 88.4\%, Bull 93.8\%, Neutral 84.9\%) shows variation across different market conditions, which is expected given the inherent differences in regime characteristics. While the standard conformal predictor shows some imbalance, the class-conditional variant achieves more balanced coverage (Bear 91.5\%, Bull 92.4\%, Neutral 89.1\%), demonstrating that the framework can be adapted to handle class imbalance effectively. This is crucial for deployment, as a method reporting 90\% overall coverage but only 70\% on the bear regime would not prove useful during periods when sound investment decisions based on trustworthy indicators matter the most.

\subsection{Portfolio Performance Trade-offs}

Analysis of the results for portfolio performance shows that a trade-off between absolute performance and risk-adjusted performance exists. The CP Conservative strategy forfeits a significant portion of overall performance (47.35\% versus 69.88\%), corresponding to a loss of 22.53 percentage points in overall return compared to a buy-and-hold strategy. However, it reduces drawdown by 66.2\% (-8.60\% versus -25.43\%) and improves the Sharpe ratio by 86.7\% (1.520 versus 0.814) for investors who are risk averse and concerned with capital preservation. The high value for the Sortino ratio (2.03 versus 1.14) confirms that the portfolio has become less volatile due to the reduction in downside risk rather than a restriction on potential upside.

The viability for practical implementation, based on transaction cost analysis, can be concluded to be true, since, based on actual retail prices of 0.10\%, the CP Conservative portfolio maintains a Sharpe ratio of 1.013, continuing to beat buy-and-hold strategies by 28.4\%. It is also worth noting that CP strategies are more sensitive to transactions, since there are 146 trades, compared to 0 trades for buy-and-hold.

\subsection{Advanced Methods and Research Contributions}

The discussion on the differential conformal prediction techniques under consideration encompasses three open challenges discussed in the recent state-of-the-art. Table \ref{tab:research_questions} lists the respective results. The class-conditional conformal prediction addresses the problem of class imbalance and achieves a 66.0\% reduction in the standard deviation of the coverage (1.57\% compared to 4.61\%), while also improving overall coverage from 89.82\% to 91.09\%. The adaptive conformal prediction keeps the coverage remaining similar to that when the model is not adapted to the changing conditions. The window size of 126 days shows the best compromise and achieves 90.38\% coverage. The hybrid model proposed here that combines both techniques achieves the best coverage balance with a standard deviation of 0.95\% (a total reduction of 79.3\% compared to the baseline model), demonstrating that combining adaptive and class-conditional approaches can effectively address both non-stationarity and class imbalance simultaneously.

\begin{table}[h]
\centering
\caption{Summary of Answers to Open Research Questions}
\label{tab:research_questions}
\begin{tabular}{@{}p{4cm}lp{3cm}@{}}
\toprule
Question & Method & Key Result \\ \midrule
Q1: Empirical validation? & Standard CP & 89.82\% coverage \\
Q2: Handle imbalance? & Class-Cond CP & Std dev: 4.61\%1.57\% \\
Q3: Adaptive calibration? & Adaptive CP & Maintains 89-90\% \\
BONUS: Combine Q2+Q3? & \textbf{Hybrid CP} & \textbf{Std dev: 0.95\%} \\ \bottomrule
\end{tabular}
\end{table}

Multi-asset validation reveals significant limitations in the introduced framework. Even if generalized over equities (coverage on average of 88.4\%), the effectiveness of algorithmic approaches does depend on assets. Results show improvement in bonds (6.9\% increase in TLT coverage, balance improvement from 10.9\% to 0.9\%), while commodities show deterioration (29.4\% decrease in GLD coverage, balance deterioration from 2.2\% to 31.9\%).

\subsection{Limitations and Future Work}

The model and results have several shortcomings: (1) It is dependent on HMM regime classifications as ground truth that may not be a complete identification of market regimes; sensitivity analysis on the choice of initial HMM conditions and number of HMM states was not explored; (2) It employs static allocation rules that are not portfolio goal optimized; this is partially addressed by Note 9 by specifying portfolio goal functions for allocation rules directly; however, whether the chosen allocation rules are globally optimal or even nearby optimal is unclear; (3) It is limited by the focus on a single asset regarding the potential for portfolio diversity; this is addressed by utilizing multiple assets for the regimes based on overall market performance; however, further work can be done by applying this model on multiple assets taking into account correlation between assets; (4) It requires careful asset-dependent calibration for various sophisticated models that may have different performance based on asset class; this is addressed in this model by accurately specifying asset classes for regimes; however, a more accurate model may be built by employing more diversified assets based on performance; (5) It has several assumptions regarding the backtest environment that can potentially lead to overestimation of performance. The comparison of training times between Gradient Boosting models and Transformers was done on a single machine with an Intel i7-10700K CPU and 32\,GB RAM for a single run. Future work can be done on multiple-asset regimes taking into account correlation between assets. It can also be extended by employing allocation strategies based on modern portfolio theory.

% FIGURE 9: Class-Conditional CP Comparison (Optional - for extended version)
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/enhanced_cp/class_conditional_cp_comparison.png}
\caption{Class-conditional conformal prediction performance showing improved coverage balance across imbalanced regime classes.}
\label{fig:class_conditional}
\end{figure}

% FIGURE 10: Adaptive CP Window Comparison (Optional - for extended version)
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/enhanced_cp/adaptive_cp_window_comparison.png}
\caption{Adaptive conformal prediction with varying calibration window sizes demonstrating robustness to non-stationarity.}
\label{fig:adaptive_window}
\end{figure}

% FIGURE 11: All Methods Comparison (Optional - for extended version)
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/enhanced_cp/all_methods_comparison.png}
\caption{Comprehensive comparison of baseline, class-conditional, adaptive, and hybrid conformal prediction methods.}
\label{fig:all_methods}
\end{figure}

% FIGURE 12: Transaction Cost Sensitivity (Optional - for extended version)
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/cp_portfolio/transaction_cost_sensitivity.png}
\caption{Portfolio performance sensitivity analysis across varying transaction cost levels.}
\label{fig:transaction_cost}
\end{figure}

% FIGURE 13: Cross-Asset Comparison (Optional - for extended version)
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/multi_asset/cross_asset_comparison.png}
\caption{Conformal prediction performance across multiple asset classes including equities, bonds, and commodities.}
\label{fig:cross_asset}
\end{figure}

% FIGURE 14: Per-Regime Coverage Heatmap (Optional - for extended version)
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/multi_asset/per_regime_coverage_heatmap.png}
\caption{Heatmap visualization of coverage rates across regimes and asset classes.}
\label{fig:coverage_heatmap}
\end{figure}

% FIGURE 15: Coverage Balance (Optional - for extended version)
\begin{figure}[h]
\centering
\includegraphics[width=0.48\textwidth]{results/multi_asset/coverage_balance.png}
\caption{Coverage balance metrics across different conformal prediction variants and asset classes.}
\label{fig:coverage_balance}
\end{figure}

\section{Conclusion}

In this article, a systematic and rigorous empirical study combining regime detection via Hidden Markov Models and conformal prediction for portfolio optimization under uncertain conditions is presented. The empirical evaluation for a period of 14 years on the S\&P 500 stock market database shows that conformal prediction is successful in achieving an empirical coverage level at 89.82\% at a significance level of $\alpha = 0.10$ with high efficiency for singleton sets at 90.2\% and average set size at 0.90. The portfolios derived using conformal predictions show improved risk-adjusted performance for uncertain market conditions using adaptive allocation. In particular, there is a reduction in drawdown risk by 66.2\% with an improved Sortino ratio of 2.03 for portfolios derived using conformal predictions, compared with a Sortino ratio for buy-and-hold portfolios at 1.14. The transaction cost analysis verifies and supports successful and effective implementation using conformal predictions. Additionally, there is improvement in Sharpe ratio by 86.7\% for investment strategies applied using this method.

It addresses three open problems that have been highlighted in recent literature. Firstly, this work provides a rigorous empirical validation for financial coverage and shows that empirical coverage remains close to the theoretical values even for non-stationary and heavy-tailed market conditions. Secondly, this work shows that class-conditional CP can efficiently deal with class imbalance and that the standard deviation for coverage decreases from 4.61\% to 1.57\%. Lastly, this work shows that adaptive CP with a sliding window for recalibration can maintain empirical coverage under non-stationarity with a window size of 126 days.

It introduces a solution that unifies adaptive calibrations with the use of quantiles dependent on the class. The experiments show that it achieves the best coverage balance across regimes, with a standard deviation of 0.95\%, representing a 79.3\% improvement over the baseline. Cross asset class validations with equities, bonds, and commodities also show asset class-dependent behavior.

The crucial point is that conformal prediction changes the definition of classifying regimes from predicting a single class to predicting a collection of potential classes with a confidence level that is supported by empirical evidence. Such a definition for quantification of uncertainties is helpful in risk management techniques that minimize risk during the transition periods between regimes and at the same time allow for complete participation in a stable regime. It is assured that observations are exchangeable, which prevents the model from being sensitive to the fat-tail properties and regimes encountered in financial markets.

The next research stage should be generalizing the proposed framework into multi-asset portfolios, taking into account correlation, and incorporating dynamic resource allocation optimization based on portfolio theory. The next research stage also involves studying online conformal prediction, adapting to a real-time setting, understanding theoretically the class-conditional method performance dependence on assets, and experimenting with other nonconformity measures that decrease the probability of empty sets while maintaining coverage. The combination of conformal prediction and the regime-based method is a very promising area of research.

\textbf{Reproducibility.} Data regarding price and volume was extracted from Yahoo Finance on October 15, 2025, while macroeconomic variables were extracted from FRED on October 15, 2025. Experiments performed on the macroeconomic model used Python 3.9 together with other software requirements for running the code, which include scikit-learn version 1.3.0, hmm learn version 0.3.0, numpy version 1.24.0, and pandas.

\section*{Appendix: Conformal Prediction to Allocation Pseudocode}

{\small
\begin{verbatim}
# Note: nonconformity score s = 1 - f(x)[y];
# alternative scores (margin-based) are possible.

Inputs:
  - Trained classifier f(x) -> probabilities
  - Calibration scores {s_i}
  - Significance level alpha
  - Allocation map w_r for each regime r
  - Test feature x_test

Compute:
  - q_hat = empirical (1-alpha)-quantile
            of {s_i}
  - threshold = 1 - q_hat
  - Gamma = { r : f(x_test)[r] >= threshold }
    # set of regimes whose probability
    # exceeds threshold

Decision rule (CP Conservative):
  if |Gamma| == 0:
    equity_weight = 0.0  # full cash
  elif |Gamma| == 1:
    equity_weight = w_r for r in Gamma
  else:
    equity_weight = min_{r in Gamma} w_r

CP Average variant replaces last line with:
  equity_weight = mean_{r in Gamma} w_r
\end{verbatim}
}

\section*{Acknowledgment}
This work was supported by Bina Nusantara University as part of the Fundamentals of Data Science course (COMP6784001) in the Computer Science Department.

\cite{barber2022,angelopoulos2021gentle,xu2021,gibbs2022,vovk2020,barber2022temporal,bastos2024conformal,gibbs2021adaptive,xu2022conformal,vovk2020online,angelopoulos2021class,romano2020classification,nanopoulos2025conformal,wisniewski2020application,angelopoulos2021uncertainty,barber2021jackknife,gibbs2022online,bae2023deep,barber2021temporal}

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}

